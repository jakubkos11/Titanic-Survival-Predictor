{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nclass TitanicPredictor:\n    \"\"\"Implements probabilistic model to predict the survival of passengers.\"\"\"\n    def __init__(self, features):\n        \"\"\"Initializes the model with a list of features to use.\"\"\"\n        self.features = features\n        self.probabilities = {}\n        self.weights = {}\n        self.threshold = 0.5\n\n    @staticmethod\n    def _print_evaluation_metrics(y_true, y_pred, dataset_name):\n        \"\"\"Prints evaluation metrics for a given dataset.\"\"\"\n        print(f\"\\n=== {dataset_name} metrics ===\")\n        print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n\n    def display_metrics(self, X_train, y_train, X_val, y_val):\n        \"\"\"Calculates and displays model accuracy on training and validation sets.\"\"\"\n        # Calculate and display metrics on training set\n        train_predictions = self.predict(X_train)\n        self._print_evaluation_metrics(y_train, train_predictions, \"Training\")\n        \n        # Calculate and display metrics on validation set\n        val_predictions = self.predict(X_val)\n        self._print_evaluation_metrics(y_val, val_predictions, \"Validation\")\n    \n    def _clean_data(self, data):\n        \"\"\"Fill the missing values in columns.\"\"\"\n        df = data.copy()\n        # Note: We dont fill Cabin, because it is late used in IsCabin feature\n        \n        # Fill with the median age grouped by Pclass and Sex for more accuracy.\n        df['Age'] = df.groupby(['Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n    \n        # In case any group was entirely NaN, fill remaining with the global median\n        if df['Age'].isnull().any():\n            df['Age'] = df['Age'].fillna(df['Age'].median())\n    \n        # Fill missing values with the median.\n        df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n    \n        # Fill the missing values with the most common port.\n        df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n        return df\n\n    def _apply_feature_engineering(self, data):\n        \"\"\"Add custom engineering features to improve predictive power of model.\"\"\"\n        df = data.copy()\n        df['FamilySize'] = df['Parch'] + df['SibSp'] + 1\n        df['HasCabin'] = df['Cabin'].notnull().astype(int)\n        df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n        df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand = False)\n        \n        # Simplify titles into few different categories\n        common_titles = ['Mr', 'Miss', 'Mrs', 'Master']\n        df['Title'] = df['Title'].apply(lambda x: x if x in common_titles else 'Other')\n        return df\n\n    def _calculate_weights(self, data):\n        \"\"\"\n        Calculates weights of certain feature based on the \n        survival rate difference between smallest and largest group.\n        \"\"\"\n        diffs = {}\n        for feature in self.features:\n            grouped = data.groupby(feature)['Survived'].mean()\n            diffs[feature] = grouped.max() - grouped.min()\n        \n        total_diff = sum(diffs.values()) or 1 # Avoid division by zero\n        return {k: v / total_diff for k, v in diffs.items()}\n\n    def _convert_probs_to_dict(self, data):\n        \"\"\"Convert each category probability weight to dictionary.\"\"\"\n        return {feature: data.groupby(feature)['Survived'].mean().to_dict() for feature in self.features}\n\n    def _calculate_weighted_score(self, row):\n        \"\"\"Calculates combined survival chance for each passenger.\"\"\"\n        score = 0\n        for feature in self.features:\n            # Use 0.5 as a default probability if a category was not seen in the training data\n            prob = self.probabilities.get(feature, {}).get(row[feature], 0.5)\n            weight = self.weights.get(feature, 0)\n            score += prob * weight\n        return score\n\n    def _find_best_threshold(self, X_val, y_val):\n        \"\"\"Finds optimal threshold for validation data.\"\"\"\n        X_val_copy = X_val.copy()\n        X_val_copy['PredictedChance'] = X_val_copy.apply(self._calculate_weighted_score, axis=1)\n            \n        best_accuracy = 0\n        best_threshold = 0.5\n        for threshold in np.arange(0.1, 0.9, 0.01):\n            predictions = (X_val_copy['PredictedChance'] >= threshold).astype(int)\n            accuracy = accuracy_score(y_val, predictions)\n            if accuracy > best_accuracy:\n                best_accuracy = accuracy\n                best_threshold = threshold\n        return best_threshold\n\n    def train_model(self, X, y):\n        \"\"\"\n        1. Splits data into training and validation sets.\n        2. Learns weights and probabilities from the training set.\n        3. Finds the optimal threshold on the validation set.\n        \"\"\"\n        # Split data into train and validation sets\n        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 1)\n    \n        # Combine features and target in training data\n        train_data = pd.concat([X_train, y_train], axis = 1)\n        \n        # Find weights and optimal threshold\n        self.weights = self._calculate_weights(train_data)\n        self.probabilities = self._convert_probs_to_dict(train_data)\n        self.threshold = self._find_best_threshold(X_val, y_val)\n\n        self.display_metrics(X_train, y_train, X_val, y_val)\n\n    def predict(self, X):\n        \"\"\"Gives final predictions for test data.\"\"\"\n        X_copy = X.copy()\n        predicted_chances = X_copy.apply(self._calculate_weighted_score, axis = 1)\n        return (predicted_chances >= self.threshold).astype(int)\n\n    def run(self):\n        # Load data\n        train_df = pd.read_csv('/kaggle/input/titanic/train.csv')\n        test_df = pd.read_csv('/kaggle/input/titanic/test.csv')\n\n        # Separate features from the target variable\n        X = train_df.drop('Survived', axis = 1)\n        y = train_df['Survived']\n        X_test = test_df\n\n        # Clean data\n        X = self._clean_data(X)\n        X_test = self._clean_data(X_test)\n\n        # Apply feature engineering\n        X = self._apply_feature_engineering(X)\n        X_test = self._apply_feature_engineering(X_test)\n\n        # Train model\n        self.train_model(X, y)\n\n        # Make predictions on the test set\n        predictions = self.predict(X_test)\n\n        # Generate the submission file\n        submission = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': predictions})\n        submission.to_csv('submission.csv', index = False)\n\n# Main function\nif __name__ == \"__main__\":\n    # Define which categorical features we want to use in our model\n    selected_features = ['Sex', 'Pclass', 'Title', 'FamilySize']\n    \n    # Create and run our model\n    predictor = TitanicPredictor(selected_features)\n    predictor.run()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T22:42:51.070971Z","iopub.execute_input":"2025-09-21T22:42:51.071815Z","iopub.status.idle":"2025-09-21T22:42:51.207827Z","shell.execute_reply.started":"2025-09-21T22:42:51.071778Z","shell.execute_reply":"2025-09-21T22:42:51.206917Z"}},"outputs":[{"name":"stdout","text":"\n=== Training metrics ===\nAccuracy: 0.8202\n\n=== Validation metrics ===\nAccuracy: 0.7989\n","output_type":"stream"}],"execution_count":6}]}